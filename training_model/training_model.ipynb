{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/649472272998528798', creation_time=1730053234207, experiment_id='649472272998528798', last_update_time=1730053234207, lifecycle_stage='active', name='LSTM Experiments', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:7777\")\n",
    "mlflow.set_experiment(\"LSTM Experiments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "############################################################################\n",
    "##################  SOME GENERAL PLOT  CONFIGURATIONS  #####################\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "sns.set_theme(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "Colour_Palette = ['#01BEFE', '#FF7D00', '#FFDD00', '#FF006D', '#ADFF02', '#8F00FF']\n",
    "sns.set_palette(sns.color_palette(Colour_Palette))\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################\n",
    "###############  YFINANCE - DOWNLOAD DATA AND CREATE DF  ###################\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price                     Adj Close                          Close             \\\n",
      "Ticker                         6L=F       BZ=F   PETR4.SA     6L=F       BZ=F   \n",
      "Date                                                                            \n",
      "2020-01-02 00:00:00+00:00   0.24810  66.250000  10.621438  0.24810  66.250000   \n",
      "2020-01-03 00:00:00+00:00   0.24655  68.599998  10.534945  0.24655  68.599998   \n",
      "2020-01-06 00:00:00+00:00   0.24625  68.910004  10.659495  0.24625  68.910004   \n",
      "2020-01-07 00:00:00+00:00   0.24590  68.269997  10.617979  0.24590  68.269997   \n",
      "2020-01-08 00:00:00+00:00   0.24695  65.440002  10.552245  0.24695  65.440002   \n",
      "\n",
      "Price                                   High                            Low  \\\n",
      "Ticker                      PETR4.SA    6L=F       BZ=F   PETR4.SA     6L=F   \n",
      "Date                                                                          \n",
      "2020-01-02 00:00:00+00:00  30.700001  0.2506  66.570000  30.700001  0.24730   \n",
      "2020-01-03 00:00:00+00:00  30.450001  0.2481  69.480003  31.240000  0.24545   \n",
      "2020-01-06 00:00:00+00:00  30.809999  0.2468  70.720001  30.940001  0.24520   \n",
      "2020-01-07 00:00:00+00:00  30.690001  0.2465  68.739998  30.879999  0.24410   \n",
      "2020-01-08 00:00:00+00:00  30.500000  0.2472  71.989998  30.770000  0.24425   \n",
      "\n",
      "Price                                              Open                        \\\n",
      "Ticker                          BZ=F   PETR4.SA    6L=F       BZ=F   PETR4.SA   \n",
      "Date                                                                            \n",
      "2020-01-02 00:00:00+00:00  65.730003  30.309999  0.2500  66.470001  30.510000   \n",
      "2020-01-03 00:00:00+00:00  66.220001  30.450001  0.2481  66.290001  30.879999   \n",
      "2020-01-06 00:00:00+00:00  68.190002  29.950001  0.2465  69.070000  30.430000   \n",
      "2020-01-07 00:00:00+00:00  67.650002  30.469999  0.2465  68.580002  30.820000   \n",
      "2020-01-08 00:00:00+00:00  64.940002  30.240000  0.2452  68.470001  30.690001   \n",
      "\n",
      "Price                      Volume                       \n",
      "Ticker                       6L=F     BZ=F    PETR4.SA  \n",
      "Date                                                    \n",
      "2020-01-02 00:00:00+00:00  5661.0  25810.0  37774500.0  \n",
      "2020-01-03 00:00:00+00:00  3605.0  78848.0  71595600.0  \n",
      "2020-01-06 00:00:00+00:00  6220.0  51933.0  81844000.0  \n",
      "2020-01-07 00:00:00+00:00  4010.0  41178.0  32822000.0  \n",
      "2020-01-08 00:00:00+00:00  4821.0  85232.0  48215600.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1244 entries, 2020-01-02 00:00:00+00:00 to 2024-10-25 00:00:00+00:00\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   (Adj Close, 6L=F)      1214 non-null   float64\n",
      " 1   (Adj Close, BZ=F)      1214 non-null   float64\n",
      " 2   (Adj Close, PETR4.SA)  1202 non-null   float64\n",
      " 3   (Close, 6L=F)          1214 non-null   float64\n",
      " 4   (Close, BZ=F)          1214 non-null   float64\n",
      " 5   (Close, PETR4.SA)      1202 non-null   float64\n",
      " 6   (High, 6L=F)           1214 non-null   float64\n",
      " 7   (High, BZ=F)           1214 non-null   float64\n",
      " 8   (High, PETR4.SA)       1202 non-null   float64\n",
      " 9   (Low, 6L=F)            1214 non-null   float64\n",
      " 10  (Low, BZ=F)            1214 non-null   float64\n",
      " 11  (Low, PETR4.SA)        1202 non-null   float64\n",
      " 12  (Open, 6L=F)           1214 non-null   float64\n",
      " 13  (Open, BZ=F)           1214 non-null   float64\n",
      " 14  (Open, PETR4.SA)       1202 non-null   float64\n",
      " 15  (Volume, 6L=F)         1214 non-null   float64\n",
      " 16  (Volume, BZ=F)         1214 non-null   float64\n",
      " 17  (Volume, PETR4.SA)     1202 non-null   float64\n",
      "dtypes: float64(18)\n",
      "memory usage: 184.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "stock_end_date = date.today().strftime(\"%Y-%m-%d\") # GRUPO : DECIDIR\n",
    "stock_start_date = '2020-01-01'                    # GRUPO : DECIDIR\n",
    "tickers = ['PETR4.SA', 'BZ=F', '6L=F']\n",
    "\n",
    "df_full = yf.download(tickers, start=stock_start_date, end=stock_end_date)\n",
    "\n",
    "# Inspect the data\n",
    "print(df_full.head())\n",
    "print(df_full.info())\n",
    "\n",
    "# Split into 1 sub DataFrame by ticker\n",
    "n_tickers = len(tickers)\n",
    "sub_df = {}\n",
    "for tk in tickers:\n",
    "    sub_df[tk] = df_full.xs(key=tk, level='Ticker', axis=1, drop_level=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################\n",
    "############  FUNCTION TO PLOT YFINANCE DATA THROUGH DATES  ################\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_fn import data_plot_multindex, data_plot\n",
    "\n",
    "# Plot the data\n",
    "# data_plot_multindex(df_full,n_tickers)\n",
    "\n",
    "# data_plot(sub_df['PETR4.SA'])\n",
    "# data_plot(sub_df['CL=F'])\n",
    "# data_plot(sub_df['BZ=F'])\n",
    "# data_plot(sub_df['6L=F'])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################\n",
    "##############  SPLIT TRAIN AND TEST DATA + RESHAPE DATA  ##################\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996\n",
      "(996, 3) (248, 3)\n",
      "(996, 3)\n",
      "(248, 3)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Selecting only Close Values for everyone\n",
    "df = df_full['Close']\n",
    "\n",
    "# Train test split\n",
    "\n",
    "def train_test_split_fn(df, train_perc_size):\n",
    "\n",
    "    training_data_len = math.ceil(len(df) * train_perc_size)     # GRUPO : DECIDIR\n",
    "    print(training_data_len)\n",
    "\n",
    "    # Splitting the dataset\n",
    "    train_data = df[:training_data_len].iloc[:, 0:n_tickers]\n",
    "    test_data = df[training_data_len:].iloc[:, :n_tickers]\n",
    "    print(train_data.shape, test_data.shape)\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = train_test_split_fn(df,train_perc_size=0.8)\n",
    "\n",
    "def reshape_to_np_array(train_data, test_data, new_size):\n",
    "\n",
    "    # Selecting Open Price values\n",
    "    dataset_train = train_data.values  # GRUPO : CLOSE\n",
    "    # Reshaping 1D to 2D array\n",
    "    dataset_train = np.reshape(dataset_train, (-1, new_size))\n",
    "\n",
    "    # Selecting Open Price values\n",
    "    dataset_test = test_data.values    # GRUPO : CLOSE\n",
    "    # Reshaping 1D to 2D array\n",
    "    dataset_test = np.reshape(dataset_test, (-1, new_size))\n",
    "\n",
    "    return dataset_train, dataset_test\n",
    "\n",
    "dataset_train, dataset_test =  reshape_to_np_array(train_data, test_data, n_tickers)\n",
    "print(dataset_train.shape)\n",
    "print(dataset_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################\n",
    "####################  SCALING DATA WITH MINMAXSCALER  ######################\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.43184536 0.71281676]\n",
      " [0.98053981 0.45347443 0.70363571]\n",
      " [0.97677346 0.45632768 0.71685638]\n",
      " [0.97237925 0.45043714 0.71244951]\n",
      " [0.98556187 0.42439025 0.70547189]]\n",
      "[[0.43377271 0.57156004 0.86044807]\n",
      " [0.43753925 0.58159222 0.89607045]\n",
      " [0.46264916 0.58113207 0.91406537]\n",
      " [0.46327682 0.56925907 0.        ]\n",
      " [0.46139364 0.53465252 0.89092908]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1),clip=True)     # GRUPO : DECIDIR\n",
    "# Scaling dataset - FIT SÓ AQUI\n",
    "scaled_train = scaler.fit_transform(dataset_train)\n",
    "np.nan_to_num(scaled_train,copy=False,nan=0.0)\n",
    "print(scaled_train[:5])\n",
    "\n",
    "# Normalizing values between 0 and 1 - AQUI SÓ TRANSFORM\n",
    "scaled_test = scaler.transform(dataset_test)\n",
    "np.nan_to_num(scaled_test,copy=False,nan=0.0)\n",
    "print(scaled_test[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################\n",
    "##############  SPLIT DATA INTO X (INPUTS) AND Y (LABLES)  #################\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(946, 50, 3) (946, 1)\n",
      "(198, 50, 3) (198, 1)\n"
     ]
    }
   ],
   "source": [
    "# COLOCAR ESSE STEP NA PIPELINE DE DADOS\n",
    "\n",
    "def create_dataset_from_moving_window(scaled_data, window_length, n_features):\n",
    "    \n",
    "    # Create sequences and labels for training data\n",
    "    L_dataset = len(scaled_data)\n",
    "    X, y = [], []\n",
    "    for i in range(L_dataset - window_length):\n",
    "        X.append(scaled_data[i:i + window_length,0:n_features])\n",
    "        y.append(scaled_data[i + window_length,n_features-1:])  # Predicting the value right after the sequence\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y\n",
    "\n",
    "W_train = 50\n",
    "W_test = 50\n",
    "X_train, y_train = create_dataset_from_moving_window(scaled_train, window_length=W_train, n_features=n_tickers)\n",
    "X_test, y_test = create_dataset_from_moving_window(scaled_test, window_length=W_test, n_features=n_tickers)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################\n",
    "################  CONVERT DATA TO PYTORCH TENSOR  ##########################\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################\n",
    "##############  CREATING LSTM CUSTOM CLASS WITH LINEAR OUT  ################\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    # AVALIAR INICIALIZAÇÃO DOS PESOS\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.linear(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################\n",
    "######################  SETUP / CONFIGS FOR TRAINING  ######################\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "input_size = n_tickers          # GRUPO : HYPERPARAMETROS\n",
    "num_layers = 10         # GRUPO : HYPERPARAMETROS\n",
    "hidden_size = 100       # GRUPO : HYPERPARAMETROS\n",
    "output_size = 1\n",
    "dropout = 0.2           # Regulatization // GRUPO : HYPERPARAMETROS\n",
    "learning_rate = 0.001  # GRUPO : HYPERPARAMETROS\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, dropout).to(device)\n",
    "loss_fn = nn.MSELoss(reduction='mean')  # GRUPO : DECIDIR\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # GRUPO : DECIDIR\n",
    "\n",
    "batch_size = 30  # GRUPO : VERIFICAR\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "num_epochs = 10  # GRUPO : HYPERPARAMETROS\n",
    "train_hist = []\n",
    "test_hist = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################\n",
    "###################  LSTM TRAINING // LSTM TRANING  ########################\n",
    "############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_log = {\n",
    "    \"start_date\" : stock_start_date,\n",
    "    \"end_date\" : stock_end_date,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"sequence_length_train\" : W_train,\n",
    "    \"sequence_length_test\" : W_test,\n",
    "    \"input_size\" : input_size,\n",
    "    \"num_layers\" : num_layers,\n",
    "    \"hidden_size\" : hidden_size,\n",
    "    \"dropout\" : dropout,\n",
    "    \"learning_rate\" : learning_rate,\n",
    "    \"num_epochs\" : num_epochs,\n",
    "    \"optimizer\" : optimizer,\n",
    "    \"loss_fn\" : loss_fn,\n",
    "}\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start_training_time = time.time()\n",
    "print(f\"Starting training: {start_training_time}\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    mlflow.set_tag(\"Fase\",\"1 - Define Baseline\")\n",
    "    mlflow.log_params(params_to_log)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            predictions = model(batch_X)\n",
    "            loss = loss_fn(predictions, batch_y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        train_hist.append(average_loss)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_test_loss = 0.0\n",
    "\n",
    "            for batch_X_test, batch_y_test in test_loader:\n",
    "                batch_X_test, batch_y_test = batch_X_test.to(device), batch_y_test.to(device)\n",
    "                predictions_test = model(batch_X_test)\n",
    "                test_loss = loss_fn(predictions_test, batch_y_test)\n",
    "\n",
    "                total_test_loss += test_loss.item()\n",
    "\n",
    "            average_test_loss = total_test_loss / len(test_loader)\n",
    "            test_hist.append(average_test_loss)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {average_loss:.4f}, Test Loss: {average_test_loss:.4f}')\n",
    "\n",
    "    end_training_time = time.time()\n",
    "    elapsed_training_time = end_training_time - start_training_time\n",
    "    print(f\"Ending training: {end_training_time}\")\n",
    "    print(f\"Elapsed Training time: {elapsed_training_time}\")\n",
    "    \n",
    "    mlflow.log_metric('training_time', elapsed_training_time)\n",
    "    mlflow.log_metric('training_loss', average_loss)\n",
    "    mlflow.log_metric('test_loss', average_test_loss)\n",
    "    \n",
    "\n",
    "    ############################################################################\n",
    "    #########################  PLOT TRAINING RESULTS  ##########################\n",
    "    ############################################################################\n",
    "\n",
    "    x = np.linspace(1,num_epochs,num_epochs)\n",
    "    plt.plot(x,train_hist,scalex=True, label=\"Training loss\")\n",
    "    plt.plot(x, test_hist, label=\"Test loss\")\n",
    "    plt.legend()\n",
    "    plt.show(block=False)\n",
    "\n",
    "    ############################################################################\n",
    "    #################### PREDICT // FORECAST RESULTS  ##########################\n",
    "    ############################################################################\n",
    "\n",
    "    num_forecast_steps = 30\n",
    "    sequence_to_plot = X_test.squeeze().cpu().numpy()\n",
    "    print(sequence_to_plot.shape)\n",
    "    historical_data = sequence_to_plot[-1]\n",
    "    print(historical_data.shape)\n",
    "\n",
    "    forecasted_values = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_forecast_steps):\n",
    "            historical_data_tensor = torch.as_tensor(historical_data).view(1, -1, n_tickers).float().to(device)\n",
    "            # print(historical_data_tensor.shape)\n",
    "            predicted_value = model(historical_data_tensor).cpu().numpy()[0, 0]\n",
    "            # print(predicted_value.shape)\n",
    "            forecasted_values.append(predicted_value)\n",
    "            historical_data = np.roll(historical_data, shift=-1)\n",
    "            historical_data[-1] = predicted_value\n",
    "\n",
    "    last_date = test_data.index[-1]\n",
    "    future_dates = pd.date_range(start=last_date + pd.DateOffset(1), periods=30)\n",
    "\n",
    "    ############################################################################\n",
    "    ####################### PLOT PREDICT // FORECAST ###########################\n",
    "    ############################################################################\n",
    "\n",
    "    from pylab import rcParams\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = [14, 4]\n",
    "    plt.plot(test_data.index[-100:], test_data[-100:], label=\"test_data\", color=\"b\")\n",
    "    plt.plot(test_data.index[-30:], test_data[-30:], label='actual values', color='green')\n",
    "    plt.plot(test_data.index[-1:].append(future_dates), np.concatenate([test_data[-1:], scaler.inverse_transform(np.array(forecasted_values).reshape(-1, 1)).flatten()]), label='forecasted values', color='red')\n",
    "\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.title('Time Series Forecasting')\n",
    "    plt.grid(True)\n",
    "    plt.show(block=False)\n",
    "\n",
    "    ############################################################################\n",
    "    #######################   PERFORMANCE METRICS   ###########################\n",
    "    ############################################################################\n",
    "\n",
    "    from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "    # Evaluate the model and calculate RMSE and R² score\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_predictions = []\n",
    "        for batch_X_test in X_test:\n",
    "            batch_X_test = batch_X_test.to(device).unsqueeze(0)  # Add batch dimension\n",
    "            test_predictions.append(model(batch_X_test).cpu().numpy().flatten()[0])\n",
    "\n",
    "    test_predictions = np.array(test_predictions)\n",
    "\n",
    "    # Calculate RMSE and R² score\n",
    "    rmse = root_mean_squared_error(y_test.cpu().numpy(), test_predictions)\n",
    "    r2 = r2_score(y_test.cpu().numpy(), test_predictions)\n",
    "\n",
    "    print(f'RMSE: {rmse:.4f}')\n",
    "    print(f'R² Score: {r2:.4f}')\n",
    "\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"R2-Score\", r2)\n",
    "\n",
    "    mlflow.end_run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
