# TECH CHALLENGE 4 - PREVIS√ÉO DE S√âRIES TEMPORAIS COM LSTM

## Overview da Solu√ß√£o

**Objetivo:**
Realizar predi√ß√£o do pre√ßo de fechamento do ativo da Petrobr√°s (PETR4.SA) 1 passo a frente (pr√≥ximo dia) usando LSTM. 

### Requisitos para subir a API
* Docker instalado.

### QuickStart

Para subir a arquitetura, navegue pelo terminal at√© o diret√≥rio contendo `docker-compose.yml` e execute o seguinte comando:
```
docker compose up -d --build
```

Os logs do container indicar√£o sucesso ao carregar o modelo com as mensagens `Model / Scaler loaded successfully`. A API est√° dispon√≠vel na porta `5000`. Voc√™ pode acessar a documenta√ß√£o-Swagger da API pelo endere√ßo: `http://localhost:5000/docs`. Para realizar uma predi√ß√£o, fa√ßa uma requisi√ß√£o POST para `http://localhost:5000/predict` contendo um `body` (*input*) an√°logo ao seguinte exemplo:
```
body = {
  "end_date": "2024-11-15",
  "start_date": "2024-06-01",
  "seq_length": 20,
  "horizon": 1
}
```

### Diret√≥rios e Arquivos

```bash
üì¶.
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ dashboard.json
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ prometheus.yml
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îú‚îÄ‚îÄ artifacts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models_tf
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ best_models
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ MLmodel
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ conda.yaml
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ model.pkl
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ python_env.yaml
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transformers
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ scaler
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ MLmodel
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ conda.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ model.pkl
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ python_env.yaml
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ concept_drift.py
‚îÇ   ‚îú‚îÄ‚îÄ data_drift.py
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ model_functions.py
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ training_model
    ‚îú‚îÄ‚îÄ Analysis.docx
    ‚îú‚îÄ‚îÄ Experiment_Design.drawio
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ api_predict.ipynb
    ‚îú‚îÄ‚îÄ img
    ‚îÇ   ‚îú‚îÄ‚îÄ lstm_architecture.png
    ‚îÇ   ‚îî‚îÄ‚îÄ mlflow_champion.png
    ‚îú‚îÄ‚îÄ parametrized_training_model.py
    ‚îú‚îÄ‚îÄ predict.ipynb
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îú‚îÄ‚îÄ training_model.ipynb
    ‚îú‚îÄ‚îÄ training_model_tf_grid_search.ipynb
    ‚îî‚îÄ‚îÄ validating_model.ipynb
```

### Por dentro da API

Ap√≥s a requisi√ß√£o, dentro dessa API, ser√° montado um Data Frame contendo os valores do(s) ativo(s) entre as datas `start_date` e `end_date`. Desta forma, internamente, tem-se um Data Frame no seguinte formato (considerando o exemplo acima com o ativo "PETR4.SA"):
```
Index | Datetime | Value
0   | '2024-06-03T00:00:00+00:00' | 36.4732551574707      -> X[0]
1   | '2024-06-04T00:00:00+00:00' | 36.06673812866211     -> X[1]
2   | '2024-06-05T00:00:00+00:00' | 36.11400604248047     -> X[2]
...
117 | '2024-11-13T00:00:00+00:00' | 36.880001068115234    -> X[117]
118 | '2024-11-14T00:00:00+00:00' | 37.27000045776367     -> X[118]
```
Al√©m disso, √© montado um conjunto de dados no formato de TimeSeries com janela m√≥vel de tamanho `seq_length`. Desta forma, dado um horizonte de predi√ß√£o igual a 1 (dia) s√£o utilizados vetores de entrada `X[a:a+seq_length]` para predizer o valor do dia seguinte `X[a+seq_length+1] = y_pred[a+seq_length+1]`, i.e.:
```
X[0:seq_length-1]   -->  y[seq_length]    
X[1:seq_length]     -->  y[seq_length+1] 
...
X[N-seq_length:N]   -->  y[N+1],           
```
que no nosso exemplo:
```
X[0:19]     -->    y_pred[20]  = 37.381282806396484 = X_pred[20]
X[1:20]     -->    y_pred[21]  = 37.739967346191406 = X_pred[21]
...
X[98:117]   -->    y_pred[118] = 37.2889518737793   = X_pred[118].
```

### Testando a API com C√≥digo Python

H√° um Jupyter Notebook contendo o exemplo de uso acima da API para que o usu√°rio possa interagir e entender melhor o seu funcionamento. Tal notebook pode ser acessado em [training_model/api_predict.ipynb](/training_model/api_predict.ipynb).

## Etapas da Solu√ß√£o

### Coleta de Dados e Pre-processamento

`feature_engineering.py`
* `get_finance_df`: obt√©m os dados do ativo desejado utilizando a biblioteca `yfinance`, que s√£o retornados em um DataFrame. Nesse m√©todo, tamb√©m √© aplicado o `pandas.interpolate()`. Temos alguns dados NAs no Dataframe. Remov√™-los faria perder informa√ß√£o. Preencher com valor default tamb√©m n√£o atende todos os cen√°rios, j√° que a m√©dia dos valores oscila muito, e os valores s√£o muito distantes de `0` tamb√©m. Neste cen√°rio, interpolate se mostrou a melhor estrat√©gia, inclusive nos testes de treinamento do modelo.

* `split_train_test_valid_df`: retorno de forma facilitada do dataframe quebrado em partes para treino e teste (e valida√ß√£o, se desej√°vel).

* `shift_drop_na_in_xy`: cria√ß√£o de uma nova coluna no DataFrame com shift temporal parametriz√°vel, que representa o horizonte de predi√ß√£o `horizon_pred`. Por conta do shift temporal, pode haver a introdu√ß√£o de NAs nos dados nos "extremos" (primeiras/√∫ltimas linhas). Logo, uma opera√ß√£o de `dropna()` √© realizada.

* `get_xx_dropna`: faz o retorno apenas dos valores do DataFrame (`df["X"].values`). Isso √© √∫til quando usamos a classe `TimeseriesGenerator` do Keras/TF em conjunto com um shift temporal de apenas 1 amostra, j√° que essa fun√ß√£o faz esse shift automaticamente. Neste caso, o uso da fun√ß√£o `shift_drop_na_in_xy` √© dispensado, por√©m, n√£o h√° como fazer um shift temporal em mais de 1 unidade de tempo.

* `TimeseriesGenerator`: gera um conjunto de dados de treinamento aplic√°vel ao cen√°rio de s√©ries temporais em modelos Auto-Regressivos (AR). Mais detalhes em [https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/TimeseriesGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/TimeseriesGenerator).

### Desenvolvimento do Modelo LSTM e Arquitetura Final

O Desenvolvimento do modelo segue os passos descritos em em [training_model/READ.ME](/training_model/README.md) e em [training_model/Experiment_Design.drawio](/training_model/Experiment_Design.drawio). 

A Arquitetura Final do Modelo Campe√£o √© dada na Figura a seguir.

![Architecture LSTM](training_model/img/lstm_architecture.png)

### Artefatos do Modelo - Save/Load Model

Os artefatos do modelo e do scaler (transforma√ß√£o) s√£o salvos na pasta [src/artifacts](/src/artifacts) a partir do script [training_model/training_model.ipynb](/training_model/training_model.ipynb), usando o `mlflow` com os comandos `log_model()` e `save_model()`. 

Tamb√©m s√£o salvos os Datasets utilizados (em diferentes formatos, como pandas Data Frame e Numpy Arrays), os par√¢metros de treinamento e as m√©tricas obtidas.

### Deploy do Modelo - API FastAPI e Docker

Para deploy do modelo, foram utilizados 3 containers docker definidos em [docker-compose.yml](/docker-compose.yml), sendo 2 deles usados no monitoramento (descrito a seguir) e um deles, chamado de `app`, para a API.

A API, estruturada em [src/main.py](/src/main.py), faz uso de fun√ß√µes auxiliares definidas em [src/feature_engineering.py](/src/feature_engineering.py) para tratamento dos dados, conforme explicado acima, e em [src/model_functions.py](/src/model_functions.py).

![containers](training_model/img/containers.png)

### Escalabilidade e Monitoramento

O monitoramento e a escalabidade s√£o tratados pelas ferramentas **Prometheus** e **Grafana**, que s√£o executados nos seus respectivos containers de mesmo nome.
O Prometheus √© o respons√°vel por monitorar e realizar o log das m√©tricas sinalizadas na API. Suas configura√ß√µes s√£o encontradas em [prometheus.yml](/prometheus.yml).
J√° o Grafana √© onde s√£o criados e mantidos os Dashboards, onde as m√©tricas logadas podem ser observadas a partir de interfaces gr√°ficas pr√©-definidas. O arquivo de configura√ß√£o do dashboard do Grafana √© o [dashboard.json](/dashboard.json)

### Trabalhos Futuros / Poss√≠veis Melhorias

Entendemos que algumas melhorias poderiam ser implementadas nesta solu√ß√£o, sendo algumas delas:

* Revis√£o das boas pr√°ticas de c√≥digo para melhor implementa√ß√£o e organiza√ß√£o das fun√ß√µes, m√©todos, classes, e chamadas na API, ou seja, aplica√ß√£o dos princ√≠pios de *Clean Code*.
* Ado√ß√£o de testes automatizados e de loggings para melhor qualidade e manuten√ß√£o do c√≥digo, como j√° feito em Tech Challenges anteriores: [tech-c-01-embrapa-api](https://github.com/chrysremes/tech-c-01-embrapa-api)
* Adi√ß√£o de um novo caminho na API que realize, dada apenas 1 data v√°lida, fa√ßa a predi√ß√£o de 1 passo a frente apenas para essa data (e n√£o para um conjunto de dados, como est√° implementado).
* Adi√ß√£o de um m√©todo que realiza a predi√ß√£o de `h` passos a frente (e n√£o apenas 1), chamando o `model.predict` de forma "iterativa".
* Cria√ß√£o de um novo modelo (ou de novos modelos / ensamble de modelos), visando melhorar a qualidade da predi√ß√£o `h` passos a frente, com `h` variando de `2` a `H`.
* Melhorias de seguran√ßa no acesso ao Grafana (atualmente, usando `admin`/`admin`).




